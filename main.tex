\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{alphabeta}
\usepackage{amsmath}
\usepackage{float}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{booktabs}  % For better looking tables
\usepackage{hyperref}
\usepackage{xcolor}

\lstset{
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  language=R,
  extendedchars=true,
  literate={β}{{\beta}}1
}

\title{Αναγνώριση Προτύπων \\ 1η Εργαστηριακή Άσκηση \\ Χειμερινό Εξάμηνο 2024-2025 \\ Ε.ΔE.ΜΜ}
\author{Σπανάκης Παναγιώτης-Αλέξιος (ΑΜ: 03400274)}
\date{08/11/2024}

\begin{document}

\maketitle
\section*{Βήμα 1}


\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \textbf{Vowel} & \textbf{Speaker} & \textbf{Pitch (Hz)} & \textbf{F1 (Hz)} & \textbf{F2 (Hz)} & \textbf{F3 (Hz)} \\ \hline
    \multirow{2}{*}{α} & man & 134.06 & 777.91 & 1217.69 & 2405.49 \\ \cline{2-6} 
                       & woman & 176.84 & 859.08 & 1837.31 & 3146.39 \\ \hline
    \multirow{2}{*}{ου} & man & 130.65 & 372.17 & 1788.73 & 2327.56 \\ \cline{2-6} 
                        & woman & 184.51 & 321.15 & 1566.12 & 2631.54 \\ \hline
    \multirow{2}{*}{ι} & man & 132.04 & 387.10 & 2047.69 & 2556.83 \\ \cline{2-6} 
                       & woman & 178.49 & 368.76 & 2259.41 & 2951.24 \\ \hline
    \end{tabular}
    \caption{Measurements for vowels by male and female speakers.}
    \label{tab:vowels}
\end{table}

\textbf{Αρχικά, Σύγκριση Θεμελιώδους Συχνότητας (Pitch):}
Όπως αναμενόταν, η μέση συχνότητα της γυναικείας ομιλήτριας (Ομιλητής 2) είναι αισθητά υψηλότερη από εκείνη του ανδρικού ομιλητή (Ομιλητής 1) 
για όλα τα φωνήεντα. Συγκεκριμένα, για το φωνήεν \textbf{"α"} ο άντρας έχει 134 Hz ενώ η γυναίκα 177 Hz, για το \textbf{"ου"} ο 
άντρας έχει 131 Hz ενώ η γυναίκα 185 Hz, και για το \textbf{"ι"} ο άντρας 132 Hz έναντι της γυναίκας στα 178 Hz. 
Αυτή η διαφορά είναι σύμφωνη με τις γενικές φωνητικές τάσεις όπου οι γυναίκες έχουν υψηλότερες συχνότητες λόγω ανατομικών διαφορών, 
όπως οι μικρότερες και πιο τεντωμένες φωνητικές χορδές.

\textbf{Παρατηρήσεις για τα Formants:}
Οι τιμές των μορφάντων (F1, F2, F3) είναι επίσης υψηλότερες για τη γυναίκα ομιλήτρια συγκριτικά με τον άντρα, 
κάτι που αναμένεται λόγω του μικρότερου φωνητικού σωλήνα, ο οποίος επηρεάζει τις συχνότητες αντήχησης και οδηγεί σε 
μεγαλύτερες τιμές για τα formants. Για παράδειγμα, για το φωνήεν \textbf{"α"}, η πρώτη μορφάντις (F1) του άνδρα είναι 
778 Hz, ενώ της γυναίκας είναι 859 Hz. Παρόμοια, η δεύτερη μορφάντις (F2) του άνδρα είναι 1218 Hz ενώ της γυναίκας 
1837 Hz, και η τρίτη (F3) του άνδρα είναι 2405 Hz έναντι 3146 Hz για τη γυναίκα. Το ίδιο μοτίβο παρατηρείται και στα υπόλοιπα φωνήεντα.

\textbf{Ειδικές Παρατηρήσεις ανά Φωνήεν:}
\begin{itemize}
    \item Για το \textbf{"α"}, παρατηρούμε υψηλότερη F1 και F2 και στους δύο ομιλητές σε σχέση με τα φωνήεντα "ου" και "ι", κάτι που δείχνει ότι το "α" είναι πιο ανοιχτό και κεντρικό φωνήεν. Οι σημαντικά υψηλότερες τιμές F2 και F3 για τη γυναίκα ομιλήτρια πιθανώς υποδεικνύουν μια πιο πρόσθια εκφορά.
    \item Το \textbf{"ου"} εμφανίζει τη χαμηλότερη F1 και στους δύο ομιλητές, κάτι που δείχνει πως πρόκειται για ένα πιο κλειστό και οπίσθιο φωνήεν. Η διαφορά της F2 ανάμεσα στους ομιλητές ενισχύει την οπίσθια θέση του φωνήεντος και για τα δύο φύλα.
    \item Για το \textbf{"ι"}, παρατηρείται υψηλή F2, ειδικά για τη γυναίκα, κάτι που συνάδει με τον πρόσθιο, υψηλό χαρακτήρα του φωνήεντος αυτού. Η κοντινή απόσταση μεταξύ F2 και F3 στη γυναικεία φωνή μπορεί να υποδηλώνει μια πιο έντονη εκφορά.
\end{itemize}

\textbf{Γενικές Διαφορές μεταξύ των Φύλων:}
Οι διαφορές στις συχνότητες της θεμελιώδους συχνότητας και των μορφάντων που παρατηρήθηκαν είναι σύμφωνες με τις κοινές φωνητικές διακρίσεις μεταξύ ανδρικών και γυναικείων φωνών, με τον ανδρικό ομιλητή να εμφανίζει χαμηλότερες συχνότητες σε όλες τις παραμέτρους.

\section*{Βήμα 2}

Η συνάρτηση \texttt{data\_parser(directory)} λειτουργεί ως εξής:

\begin{enumerate}
    \item \textbf{Αρχικοποίηση}: Δημιουργεί τρεις κενές λίστες (\texttt{wavs}, \texttt{speakers}, \texttt{digits}).
    \item \textbf{Διάβασμα Αρχείων}: Διατρέχει όλα τα αρχεία στον καθορισμένο κατάλογο.
    \item \textbf{Φόρτωση Ήχου}: Φορτώνει κάθε αρχείο ήχου με συχνότητα 16kHz και προσθέτει τα δεδομένα στη λίστα \texttt{wavs}.
    \item \textbf{Εξαγωγή Πληροφοριών}: Από το όνομα του αρχείου, χρησιμοποιεί κανονική έκφραση για να εξάγει το ψηφίο και τον αριθμό του ομιλητή, τα οποία προστίθενται στις λίστες \texttt{digits} και \texttt{speakers} αντίστοιχα.
    \item \textbf{Επιστροφή Αποτελεσμάτων}: Επιστρέφει τις τρεις λίστες με τα ηχητικά δεδομένα, τους ομιλητές και τα ψηφία.
\end{enumerate}

\section*{Βήμα 3}

Η συνάρτηση \texttt{extract\_mfccs(wavs)} λειτουργεί ως εξής:

\begin{enumerate}
    \item \textbf{Αρχικοποίηση}: Δημιουργεί μια κενή λίστα \texttt{mfccs} για την αποθήκευση των χαρακτηριστικών.
    \item \textbf{Εξαγωγή MFCCs}: Για κάθε ήχο στη λίστα \texttt{wavs}, εξάγει 13 Mel-Frequency Cepstral Coefficients (MFCCs) χρησιμοποιώντας παράθυρο μήκους 25 ms και βήμα 10 ms (\texttt{n\_fft=400}, \texttt{hop\_length=160}).
    \item \textbf{Υπολογισμός Deltas}: Υπολογίζει την πρώτη (\texttt{delta}) και δεύτερη (\texttt{delta2}) τοπική παράγωγο των MFCCs.
    \item \textbf{Αποθήκευση Χαρακτηριστικών}: Προσθέτει τα MFCCs, τα deltas και τα delta-deltas ως ένα tuple στη λίστα \texttt{mfccs}.
    \item \textbf{Επιστροφή Αποτελεσμάτων}: Επιστρέφει τη λίστα \texttt{mfccs} με τα εξαγόμενα χαρακτηριστικά για κάθε αρχείο ήχου.
\end{enumerate}

\section*{Βήμα 4}

Τα ψηφία που αναλύθηκαν είναι $n1=7$ και $n2=4$ του 1ου και 2ου MFCC αντίστοιχα. Τα ιστογράμματα των ψηφίων αυτών για τα πρώτα 2 MFCCs παρουσιάζονται στα
Σχήματα \ref{fig:hist1} και \ref{fig:hist2}. Η διακύμανση των MFCCs για τα δύο ψηφία φαίνεται στον πίνακα \ref{tab:variance}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/histograms_seven.png}
    \caption{Ιστόγραμμα του ψηφίου "seven" για τους δύο MFCCs.}
    \label{fig:hist1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/histograms_four.png}
    \caption{Ιστόγραμμα του ψηφίου "four" για τους δύο MFCCs.}
    \label{fig:hist2}
\end{figure}


\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Digit} & \textbf{MFCC 1} & \textbf{MFCC 2} \\ \hline
    seven & 21497.80 & 3068.08 \\ \hline
    four & 14009.79 & 4906.44 \\ \hline
    \end{tabular}
    \caption{Variance of MFCCs for digits "seven" and "four".}
    \label{tab:variance}
\end{table}

Mπορούμε να εξάγουμε τα εξής συμπεράσματα:

Πρώτον, παρατηρείται σημαντική διαφορά στη διακύμανση των δύο πρώτων MFCC χαρακτηριστικών μεταξύ των ψηφίων "seven" και "four". 
Συγκεκριμένα, το MFCC1 του "seven" παρουσιάζει πολύ μεγαλύτερη διακύμανση σε σύγκριση με το "four" (21497.80 έναντι 14008.79), 
ενώ η διακύμανση του MFCC2 παρουσιάζει επίσης διαφορά, αν και μικρότερη (3068.08 για το "seven" και 4096.44 για το "four").

Δεύτερον, τα ιστογράμματα των MFCC1 και MFCC2 δείχνουν ότι οι κατανομές των δύο ψηφίων διαφέρουν αρκετά, 
ειδικά για το MFCC1, όπου το "seven" εμφανίζει υψηλότερες τιμές στην κατανομή του σε σύγκριση με το "four". 
Το MFCC2, αν και εμφανίζει λιγότερο έντονες διαφορές, διατηρεί διακριτό μοτίβο ανάμεσα στα δύο ψηφία, 
το οποίο μπορεί να χρησιμοποιηθεί για την αναγνώρισή τους.

Συμπερασματικά, η διαφορά στη διακύμανση και στην κατανομή των MFCC χαρακτηριστικών υποδηλώνει ότι τα MFCC1 και 
MFCC2 μπορούν να χρησιμοποιηθούν για τη διάκριση των ψηφίων "seven" και "four" σε ένα classification σύστημα. 
Οι διαφορετικές κατανομές δείχνουν ότι υπάρχουν χαρακτηριστικά στις συχνότητες των εκφωνήσεων που 
διαχωρίζουν τα δύο ψηφία, γεγονός που ενισχύει την απόδοση σε εφαρμογές αναγνώρισης ομιλίας.

Για την ανάλυση των χαρακτηριστικών των ψηφίων "seven" και "four" από δύο διαφορετικούς ομιλητές, 
εξάγαμε και αναπαραστήσαμε τις συσχετίσεις των Mel Filterbank Spectral Coefficients (MFSCs) και των Mel-Frequency Cepstral Coefficients (MFCCs). 
Τα αποτελέσματα παρουσιάζονται στα διαγράμματα που φαίνονται στις Εικόνες~\ref{fig:mfsc_correlation} και~\ref{fig:mfcc_correlation}.

Στην Εικόνα~\ref{fig:mfsc_correlation}, παρατηρείται ότι οι συσχετίσεις μεταξύ των MFSCs είναι υψηλές και ομοιόμορφες, 
ιδιαίτερα στα κατώτερα MFSCs, όπου εμφανίζεται έντονη συσχέτιση. Αυτό υποδηλώνει ότι τα MFSCs 
έχουν μεγαλύτερη εξάρτηση μεταξύ των συστατικών τους, κάτι που μπορεί να οφείλεται στις ακατέργαστες 
συχνότητες χωρίς την εφαρμογή του μετασχηματισμού DCT. Η ομοιόμορφη κατανομή των υψηλών συσχετίσεων 
δείχνει ότι τα MFSCs περιέχουν πλεονάζουσες πληροφορίες, οι οποίες μπορεί να επηρεάσουν την 
αποτελεσματικότητα ενός classification συστήματος, καθώς δεν διαχωρίζονται εύκολα τα χρήσιμα χαρακτηριστικά από τον θόρυβο.
Γενικότερα, για την εκπαίδευση των ταξινομητών, τα χαρακτηριστικά που χρησιμοποιούνται πρέπει να είναι ανεξάρτητα και 
να μη συσχετίζονται μεταξύ τους, κάτι που δεν παρατηρείται στα MFSCs.

Αντίθετα, η Εικόνα~\ref{fig:mfcc_correlation} δείχνει τις συσχετίσεις των MFCCs, όπου παρατηρείται ότι
οι συσχετίσεις είναι πιο ποικίλες, με χαμηλότερη ομοιομορφία και λιγότερη εξάρτηση μεταξύ των χαρακτηριστικών. 
Αυτό οφείλεται στη χρήση του μετασχηματισμού DCT, ο οποίος μειώνει τη συσχέτιση μεταξύ των MFCCs, 
διατηρώντας κυρίως τα σημαντικά φασματικά χαρακτηριστικά και αφαιρώντας τον θόρυβο. Έτσι, τα 
MFCCs αποτελούν πιο διακριτά χαρακτηριστικά που διευκολύνουν τη διάκριση μεταξύ των ψηφίων και των διαφορετικών ομιλητών.

Συμπερασματικά, η χρήση των MFCCs αντί των MFSCs είναι προτιμότερη σε συστήματα αναγνώρισης ομιλίας, 
καθώς τα MFCCs προσφέρουν καλύτερη διακριτικότητα και μικρότερη πλεοναστικότητα στις πληροφορίες. 
Ο μετασχηματισμός DCT βοηθά στην απομάκρυνση των ανεπιθύμητων συσχετίσεων και στη διατήρηση των 
σημαντικών φωνητικών χαρακτηριστικών, γεγονός που οδηγεί σε καλύτερη απόδοση των ταξινομητικών συστημάτων.


\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/corr_mfsc_combined.png}
  \caption{Συσχέτιση MFSCs για τα ψηφία "seven" και "four" από δύο ομιλητές.}
  \label{fig:mfsc_correlation}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{images/corr_mfcc_combined.png}
  \caption{Συσχέτιση MFCCs για τα ψηφία "seven" και "four" από δύο ομιλητές.}
  \label{fig:mfcc_correlation}
\end{figure}

\section*{Βήμα 5}

Για την προσέγγιση αναγνώρισης ψηφίων, πραγματοποιήθηκε η εξαγωγή ενός μοναδικού διανύσματος χαρακτηριστικών για κάθε εκφώνηση. Συγκεκριμένα, τα χαρακτηριστικά MFCCs, οι πρώτες διαφορές (deltas) και οι δεύτερες διαφορές (delta-deltas) συνδυάστηκαν σε ένα ενιαίο σύνολο χαρακτηριστικών. Για κάθε εκφώνηση υπολογίστηκε η μέση τιμή και η τυπική απόκλιση κάθε χαρακτηριστικού σε όλα τα παράθυρα της εκφώνησης, ώστε να προκύψει ένα διάνυσμα με συνολικά 78 διαστάσεις για κάθε εκφώνηση.

Στη συνέχεια, απεικονίστηκαν οι πρώτες δύο διαστάσεις αυτών των διανυσμάτων χαρακτηριστικών (δηλαδή η μέση τιμή και διακύμανση του πρώτου χαρακτηριστικού) σε ένα διάγραμμα διασποράς (scatter plot), όπου κάθε ψηφίο αναπαρίσταται με διαφορετικό χρώμα και σύμβολο (βλ. Εικόνα~\ref{fig:scatter_plot_feature_vectors}).

\textbf{Σχολιασμός Διαγράμματος}

Από το διάγραμμα παρατηρούμε ότι τα διαφορετικά ψηφία σχηματίζουν ξεχωριστά clusters στο χώρο των χαρακτηριστικών, κάτι που δείχνει ότι τα διανύσματα χαρακτηριστικών διαχωρίζονται επαρκώς για κάθε ψηφίο. Υπάρχουν, βέβαια, κάποιες αλληλοεπικαλύψεις μεταξύ ορισμένων ψηφίων, γεγονός που υποδηλώνει ότι ορισμένα ψηφία έχουν πιο όμοια φασματικά χαρακτηριστικά και μπορεί να χρειαστεί περαιτέρω επεξεργασία ή βελτιστοποίηση για την πλήρη διάκρισή τους.

Η διακριτότητα των clusters υποδηλώνει ότι τα MFCCs, μαζί με τις πρώτες και δεύτερες διαφορές τους, 
αποτελούν αποτελεσματικά χαρακτηριστικά για την αναγνώριση ομιλίας και τον διαχωρισμό των ψηφίων. Επομένως, 
η παρούσα προσέγγιση μπορεί να χρησιμοποιηθεί ως αρχική βάση για την ταξινόμηση των ψηφίων, 
με πιθανή βελτίωση μέσω επιπρόσθετων τεχνικών ή ταξινομητών.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/feature_vectors_scatterplot.png}
    \caption{Scatter Plot των διανυσμάτων χαρακτηριστικών (Πρώτες δύο διαστάσεις) για τα ψηφία "eight", "five", "four", "nine", "one", "seven", "six", "three" και "two". Κάθε ψηφίο αναπαρίσταται με διαφορετικό χρώμα και σύμβολο.}
    \label{fig:scatter_plot_feature_vectors}
\end{figure}

\section*{Βήμα 6}

Για την απεικόνιση των πολυδιάστατων διανυσμάτων χαρακτηριστικών που δημιουργήθηκαν από τα MFCCs, εφαρμόσαμε μείωση διαστάσεων μέσω Principal Component Analysis (PCA). Αρχικά, μειώσαμε τα διανύσματα σε δύο διαστάσεις και δημιουργήσαμε ένα δισδιάστατο διάγραμμα διασποράς (scatter plot), ενώ στη συνέχεια μειώσαμε σε τρεις διαστάσεις και δημιουργήσαμε ένα τρισδιάστατο scatter plot.

Σύμφωνα με τα αποτελέσματα που προέκυψαν από την ανάλυση PCA, 
οι δύο πρώτες κύριες συνιστώσες διατηρούν 20.07\%
της αρχικής διασποράς των δεδομένων (11.21\% και 8.86\% για την πρώτη και δεύτερη συνιστώσα αντίστοιχα), 
ενώ οι τρεις πρώτες κύριες συνιστώσες διατηρούν **28.09\% της διασποράς (11.21\%, 8.86\%, και 8.02\% για
την πρώτη, δεύτερη και τρίτη συνιστώσα αντίστοιχα). Η πληροφορία αυτή μας δείχνει ότι οι πρώτες τρεις
συνιστώσες καταφέρνουν να συγκρατήσουν σημαντικό ποσοστό της αρχικής διασποράς, αν και όχι τόσο μεγάλο ώστε να εξηγούν πλήρως τα δεδομένα.


\begin{enumerate}
  \item Στο δισδιάστατο διάγραμμα (Εικόνα~\ref{fig:pca_2d_plot}), τα σημεία που αντιπροσωπεύουν τα διαφορετικά ψηφία κατανέμονται μερικώς διακριτά, με κάποια clusters να είναι εμφανή. Ωστόσο, υπάρχει ακόμα κάποια αλληλοεπικάλυψη μεταξύ των σημείων για ορισμένα ψηφία, υποδεικνύοντας ότι η μείωση σε δύο διαστάσεις δεν είναι αρκετή για πλήρη διαχωρισμό των ψηφίων.

  \item Στο τρισδιάστατο διάγραμμα (Εικόνα~\ref{fig:pca_3d_plot}), η επιπλέον διάσταση προσθέτει λίγο περισσότερη διακριτότητα, αλλά εξακολουθούν να υπάρχουν επικαλύψεις. Η τρίτη διάσταση αυξάνει το ποσοστό της διασποράς που εξηγείται, ωστόσο η οπτική διάκριση παραμένει μερική.

\end{enumerate}

Η μείωση των διαστάσεων με PCA ήταν μερικώς επιτυχής. Αν και διατήρησε ένα σημαντικό ποσοστό της αρχικής διασποράς, οι πρώτες δύο και τρεις κύριες συνιστώσες δεν αρκούν για τον πλήρη διαχωρισμό των ψηφίων, λόγω της πολυπλοκότητας και της αλληλεξάρτησης των χαρακτηριστικών στα δεδομένα. Η προσθήκη επιπλέον συνιστωσών ενδέχεται να βοηθήσει, αλλά θα οδηγήσει σε μεγαλύτερη πολυπλοκότητα στην οπτικοποίηση. Παρ' όλα αυτά, η χρήση του PCA αποτελεί μια αποτελεσματική τεχνική για τη μείωση της διάστασης και την αρχική κατανόηση της κατανομής των χαρακτηριστικών.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/pca_2d_plot.png}
    \caption{PCA Scatter Plot σε δύο διαστάσεις για τα χαρακτηριστικά των ψηφίων.}
    \label{fig:pca_2d_plot}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/pca_3d_plot.png}
    \caption{PCA Scatter Plot σε τρεις διαστάσεις για τα χαρακτηριστικά των ψηφίων.}
    \label{fig:pca_3d_plot}
\end{figure}

\section*{Βήμα 7}

\textbf{Διαδικασία Ανάλυσης}

\begin{itemize}
    \item \textbf{Διαίρεση Εκπαίδευσης και Ελέγχου:} Χωρίσαμε τα δεδομένα μας σε ένα σύνολο εκπαίδευσης (70\%) και ένα σύνολο δοκιμής (30\%) για να διασφαλίσουμε ότι οι αξιολογήσεις μας είναι αμερόληπτες.
    
    \item \textbf{Μοντέλα Ταξινόμησης:} Εφαρμόσαμε και αξιολογήσαμε τους ακόλουθους ταξινομητές:
    \begin{enumerate}
        \item \textbf{Custom Bayesian Classifier:} Ένας custom Bayesian ταξινομητής που υπολογίζει πιθανότητες, μέσες τιμές και διασπορές για κάθε κατηγορία και χρησιμοποιεί Gaussian πιθανότητες για προβλέψεις.
        \item \textbf{Gaussian Naive Bayes (Scikit-Learn):} Ένα κλασικό μοντέλο Naive Bayes με Gaussian υποθέσεις για συνεχή δεδομένα.
        \item \textbf{Support Vector Machine (SVM):} Χρησιμοποιήσαμε έναν γραμμικό πυρήνα, με σκοπό να βρούμε ένα όριο απόφασης που μεγιστοποιεί το περιθώριο μεταξύ των κατηγοριών.
        \item \textbf{Random Forest:} Ένα ensemble μοντέλο που συνδυάζει τις προβλέψεις πολλαπλών δέντρων απόφασης για να αυξήσει την αξιοπιστία της ταξινόμησης.
        \item \textbf{CatBoost Classifier:} Ένα μοντέλο gradient boosting βελτιστοποιημένο για κατηγορηματικά δεδομένα, το οποίο δοκιμάσαμε με παραμέτρους προεπιλογής για πολυκατηγοριακή ταξινόμηση.
    \end{enumerate}
    
    \item \textbf{Κανονικοποίηση:} Κάθε ταξινομητής εκπαιδεύτηκε μέσα από pipeline που κανονικοποιεί τα δεδομένα εισόδου με standard scaling, βελτιώνοντας την απόδοση των ταξινομητών με κεντροποίηση δεδομένων γύρω από τη μηδενική μέση τιμή και την τυπική απόκλιση στο 1.

    \item \textbf{Μετρικές Αξιολόγησης:}
    \begin{itemize}
        \item \textbf{Ακρίβεια:} Το ποσοστό των σωστών ταξινομήσεων.
        \item \textbf{F1 Score:} Μια ισορροπημένη μέτρηση που συνδυάζει precision και recall.
        \item \textbf{Confusion Matrix:} Ένας πίνακας που οπτικοποιεί τη σύγκριση των πραγματικών και προβλεπόμενων κατηγοριών, παρέχοντας πληροφορίες για την απόδοση σε επίπεδο κατηγορίας.
    \end{itemize}
\end{itemize}

\textbf{Αποτελέσματα και Παρατηρήσεις}

Παρατηρήσαμε τα εξής από τους πίνακες σύγχυσης για κάθε ταξινομητή:

\begin{itemize}
    \item Οι \textbf{Custom Bayesian} και \textbf{Gaussian Naive Bayes} παρουσίασαν παρόμοια απόδοση, με ισορροπημένα αποτελέσματα μεταξύ των κατηγοριών, αλλά ορισμένες χαρακτηριστικές λανθασμένες ταξινομήσεις.
    \item Ο \textbf{SVM} απέδωσε καλά σε ορισμένες κατηγορίες αλλά εμφάνισε χαμηλότερη απόδοση σε συγκεκριμένα ψηφία, πιθανότατα λόγω της εξάρτησής του από γραμμικά όρια απόφασης.
    \item Ο \textbf{Random Forest} παρουσίασε βελτιωμένη ακρίβεια σε ορισμένες κατηγορίες, εκμεταλλευόμενος την ensemble προσέγγισή του για να μειώσει τη διακύμανση στις προβλέψεις.
    \item Ο \textbf{CatBoost} προσέφερε αξιόπιστα αποτελέσματα, με καλή απόδοση στις περισσότερες κατηγορίες, δείχνοντας την ικανότητά του να χειρίζεται περίπλοκες κατανομές δεδομένων.
\end{itemize}

\subsection{Bonus - Προσθήκη Επιπλέον Χαρακτηριστικών}

Για περαιτέρω βελτίωση της ακρίβειας της ταξινόμησης, πειραματιστήκαμε με την προσθήκη επιπλέον ηχητικών χαρακτηριστικών, όπως:
\begin{itemize}
    \item \textbf{Zero-Crossing Rate (ZCR):} Μετράει τον ρυθμό αλλαγής του προσήμου του σήματος, υποδεικνύοντας την πολυπλοκότητα ή το θόρυβο του σήματος.
    \item \textbf{Spectral Centroid:} Αντιπροσωπεύει το "κέντρο μάζας" του φάσματος, παρέχοντας πληροφορίες για τη φωτεινότητα του σήματος.
\end{itemize}
Με αυτά τα επιπλέον χαρακτηριστικά, επαναεκπαιδεύσαμε και αξιολογήσαμε κάθε ταξινομητή. Η επίδραση αυτών των χαρακτηριστικών στην ακρίβεια και το F1 score ήταν μικτή, κάτι που δείχνει ότι ενώ ενδέχεται να βελτιώνουν την απόδοση για ορισμένες κατηγορίες, μπορεί να μην προσθέτουν σημαντική πληροφορία σε ήδη πλούσια χαρακτηριστικά όπως τα MFCCs.

\textbf{Σύνοψη}

Τα αποτελέσματα του κάθε ταξινομητή δείχνουν διάφορα επίπεδα ακρίβειας και F1 score. Τα επιπλέον χαρακτηριστικά βελτίωσαν την απόδοση οριακά για ορισμένα μοντέλα, αλλά η αποτελεσματικότητά τους δεν ήταν σταθερή σε όλους τους ταξινομητές. Οι ταξινομητές Random Forest και CatBoost έδειξαν τις μεγαλύτερες δυνατότητες, κυρίως λόγω της ευελιξίας τους και της ικανότητάς τους να χειρίζονται πιο σύνθετα σύνολα χαρακτηριστικών.

\textbf{Κύριο Συμπέρασμα:} Τα ensemble μοντέλα, όπως το Random Forest, και τα μοντέλα boosting, όπως το CatBoost, προσφέρουν πλεονέκτημα σε σύνθετες ταξινομήσεις με πλούσια χαρακτηριστικά, ενώ πιο απλά μοντέλα, όπως το Gaussian Naive Bayes, προσφέρουν μια βάση σύγκρισης. Η προσθήκη επιπλέον χαρακτηριστικών ενδέχεται να βελτιώσει την ταξινόμηση, αλλά απαιτείται προσεκτική επιλογή χαρακτηριστικών για να αποφευχθεί η υπερφόρτωση του μοντέλου με ενδεχομένως άσχετες πληροφορίες.


\section*{Βήμα 7}

Για την ταξινόμηση των ηχητικών δεδομένων, ακολουθήθηκε η εξής διαδικασία:

Αρχικά, τα δεδομένα χωρίστηκαν σε σύνολα εκπαίδευσης (70\%) και ελέγχου (30\%) 
χρησιμοποιώντας τη συνάρτηση \texttt{train\_test\_split} με \texttt{stratify=labels} 
για να διασφαλιστεί η ισορροπημένη κατανομή των κλάσεων. Πριν την εκπαίδευση, 
εφαρμόστηκε κανονικοποίηση στα δεδομένα χρησιμοποιώντας το \texttt{StandardScaler}.

Χρησιμοποιήθηκαν συνολικά 5 ταξινομητές:
\begin{enumerate}
   \item Custom Bayesian (από την πρώτη εργαστηριακή άσκηση)
   \item Gaussian Naive Bayes (από scikit-learn)
   \item SVM (με γραμμικό kernel)
   \item Random Forest (με 100 δέντρα)
   \item CatBoost
\end{enumerate}

Τα αρχικά αποτελέσματα έδειξαν παρόμοια απόδοση για όλους τους ταξινομητές:

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Ταξινομητής} & \textbf{Ακρίβεια} & \textbf{F1-Score} \\
\hline
Custom Bayesian & 65.00\% & 63.51\% \\
Gaussian Naive Bayes & 65.00\% & 63.51\% \\
SVM & 65.00\% & 62.52\% \\
Random Forest & 65.00\% & 64.82\% \\
CatBoost & 67.50\% & 65.30\% \\
\hline
\end{tabular}
\caption{Αρχικά αποτελέσματα ταξινόμησης}
\end{table}

\textbf{Bonus: Προσθήκη Επιπλέον Χαρακτηριστικών}

Για το bonus μέρος, προστέθηκαν επιπλέον χαρακτηριστικά στο διάνυσμα:

\begin{enumerate}
   \item Zero-Crossing Rate (ZCR): Αποτελεί ένα από τα βασικότερα χαρακτηριστικά στο πεδίο του χρόνου 
   και υπολογίζει το ρυθμό με τον οποίο το σήμα αλλάζει πρόσημο \cite{kedem1986spectral}. Είναι ιδιαίτερα 
   χρήσιμο για την αναγνώριση ομιλίας καθώς συσχετίζεται με το φασματικό περιεχόμενο του σήματος \cite{bachu2010voiced}.
   
   \item Πολυωνυμικά χαρακτηριστικά (Polynomial Features): Χρησιμοποιούνται για την καταγραφή της 
   φασματικής παραμόρφωσης και την εκτίμηση της φασματικής περιβάλλουσας \cite{noll1967cepstrum}. Παρέχουν 
   πληροφορίες για τη δομή των αρμονικών συχνοτήτων του σήματος.
\end{enumerate}

Η προσθήκη των επιπλέον χαρακτηριστικών οδήγησε σε σημαντική βελτίωση των αποτελεσμάτων:

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\hline
\textbf{Ταξινομητής} & \textbf{Ακρίβεια} & \textbf{F1-Score} & \textbf{Βελτίωση Ακρίβειας} \\
\hline
Custom Bayesian & 65.00\% & 63.84\% & 0\% \\
Gaussian Naive Bayes & 65.00\% & 63.84\% & 0\% \\
SVM & 72.50\% & 72.16\% & +7.5\% \\
Random Forest & 62.50\% & 63.31\% & -2.5\% \\
CatBoost & 80.00\% & 79.94\% & +12.5\% \\
\hline
\end{tabular}
\caption{Αποτελέσματα μετά την προσθήκη επιπλέον χαρακτηριστικών}
\end{table}

\textbf{Συμπεράσματα}

Η σημαντική βελτίωση μπορεί να αποδοθεί στο ότι τα επιπρόσθετα χαρακτηριστικά παρείχαν 
συμπληρωματική πληροφορία για τη διάκριση των ψηφίων, ιδιαίτερα το ZCR που καταγράφει 
τις μεταβολές του σήματος στο πεδίο του χρόνου και τα πολυωνυμικά χαρακτηριστικά που 
αποτυπώνουν επιπλέον πληροφορία στο πεδίο της συχνότητας. Ο CatBoost φαίνεται να 
αξιοποίησε καλύτερα αυτή την επιπρόσθετη πληροφορία, οδηγώντας στη σημαντική βελτίωση 
της απόδοσής του τόσο στην ακρίβεια όσο και στο F1-Score (79.94\%). Αξιοσημείωτη 
είναι επίσης η βελτίωση του SVM, που πέτυχε F1-Score 72.16\%. Αντίθετα, οι Bayesian 
ταξινομητές και ο Random Forest δεν κατάφεραν να αξιοποιήσουν αποτελεσματικά τα 
επιπλέον χαρακτηριστικά.

\section*{Βήμα 8}




\section*{Αναγνώριση Ψηφίων με GMM-HMM}

\subsection*{Βήμα 9: Διαχωρισμός Δεδομένων}

Αρχικά, τα δεδομένα εκπαίδευσης διαχωρίστηκαν σε training και validation set με αναλογία 80\%-20\% χρησιμοποιώντας τη συνάρτηση \texttt{train\_test\_split} της βιβλιοθήκης scikit-learn. Η παράμετρος \texttt{stratify=labels} εξασφάλισε την ισορροπημένη κατανομή των ψηφίων στα δύο σύνολα:

\begin{verbatim}
X_train, X_val, y_train, y_val, spk_train, spk_val = train_test_split(
   X, y, spk, test_size=0.2, random_state=42, stratify=y)
\end{verbatim}

\subsection*{Βήμα 10: Υλοποίηση GMM-HMM}

\subsubsection*{Αρχικοποίηση Μοντέλου}
Υλοποιήθηκε ένα GMM-HMM μοντέλο για κάθε ψηφίο με τις εξής προδιαγραφές:

\begin{itemize}
   \item \texttt{n\_states = 2}: Αριθμός καταστάσεων HMM
   \item \texttt{n\_mixtures = 2}: Αριθμός Gaussian κατανομών στο μείγμα
   \item \texttt{covariance\_type = "diag"}: Διαγώνιος πίνακας συνδιακύμανσης
\end{itemize}

\subsubsection*{Δομή Left-Right HMM}
Ο πίνακας μεταβάσεων $A = \{a_{ij}\}$ αρχικοποιήθηκε ως left-right με τους εξής περιορισμούς:
\begin{itemize}
   \item $a_{ij} = 0$ για $j < i$ (απαγόρευση μεταβάσεων προς τα πίσω)
   \item $a_{ij} = 0$ για $j > i + 1$ (επιτρέπονται μόνο μεταβάσεις σε διαδοχικές καταστάσεις)
   \item Αρχικές πιθανότητες: $\pi_i = \begin{cases} 1 & \text{για } i = 1 \\ 0 & \text{για } i \neq 1 \end{cases}$
\end{itemize}

\subsection*{Εκπαίδευση με τον Αλγόριθμο EM (Baum-Welch)}

Η εκπαίδευση των GMM-HMM μοντέλων πραγματοποιήθηκε με τον αλγόριθμο Baum-Welch (ειδική περίπτωση του EM) μέσω της μεθόδου \texttt{fit} της βιβλιοθήκης Pomegranate:

\begin{verbatim}
model = DenseHMM(
   distributions=emission_model,
   edges=A,
   starts=start_probs,
   ends=end_probs,
   verbose=True
).fit(data)
\end{verbatim}

Ο αλγόριθμος εκτελεί επαναληπτικά:

\begin{enumerate}
   \item \textbf{E-step (Expectation)}:
   \begin{itemize}
       \item Forward-backward αλγόριθμος για υπολογισμό αναμενόμενων μεταβάσεων
       \item Υπολογισμός πιθανοτήτων κρυφών καταστάσεων
   \end{itemize}

   \item \textbf{M-step (Maximization)}:
   \begin{itemize}
       \item Ενημέρωση παραμέτρων GMM
       \item Επανεκτίμηση πιθανοτήτων μετάβασης
       \item Βελτιστοποίηση για μεγιστοποίηση πιθανοφάνειας
   \end{itemize}
\end{enumerate}

\subsection*{Αξιολόγηση Μοντέλου}

Για την αξιολόγηση του μοντέλου:

\begin{itemize}
   \item Υπολογίστηκαν προβλέψεις για κάθε ακολουθία χρησιμοποιώντας τη μέθοδο \texttt{predict}
   \item Υπολογίστηκε το σκορ ακρίβειας στο validation και test set
   \item Δημιουργήθηκαν πίνακες σύγχυσης για οπτικοποίηση των αποτελεσμάτων
\end{itemize}


\bibliographystyle{plainnat}
\bibliography{references}

\end{document}